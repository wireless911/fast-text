import multiprocessing
import os

from collections import defaultdict
from time import time
from typing import Text

import fasttext
import numpy as np
from fasttext import load_model
from fasttext.FastText import _FastText

"""
          训练一个监督模型, 返回一个模型对象

          @param input:           训练数据文件路径
          @param lr:              学习率
          @param dim:             向量维度
          @param ws:              cbow模型时使用
          @param epoch:           次数
          @param minCount:        词频阈值, 小于该值在初始化时会过滤掉
          @param minCountLabel:   类别阈值，类别小于该值初始化时会过滤掉
          @param minn:            构造subword时最小char个数
          @param maxn:            构造subword时最大char个数
          @param neg:             负采样
          @param wordNgrams:      n-gram个数
          @param loss:            损失函数类型, softmax, ns: 负采样, hs: 分层softmax
          @param bucket:          词扩充大小, [A, B]: A语料中包含的词向量, B不在语料中的词向量
          @param thread:          线程个数, 每个线程处理输入数据的一段, 0号线程负责loss输出
          @param lrUpdateRate:    学习率更新
          @param t:               负采样阈值
          @param label:           类别前缀
          @param verbose:         ??
          @param pretrainedVectors: 预训练的词向量文件路径, 如果word出现在文件夹中初始化不再随机
          @return model object
 """


def train_model(input=None, opt=None, model='', dim=100, epoch=5, lr=0.1, loss='softmax',
                autotuneValidationFile=None):
    np.set_printoptions(suppress=True)
    if os.path.isfile(model):
        classifier = fasttext.load_model(model)
    elif autotuneValidationFile:
        classifier = fasttext.train_supervised(input, label='__label__', autotuneValidationFile=autotuneValidationFile)
    else:
        classifier = fasttext.train_supervised(input, label='__label__', dim=dim, epoch=epoch,
                                               lr=lr, wordNgrams=2, loss=loss)
    classifier.save_model(opt)
    return classifier


dim = 100
lr = 5
epoch = 5
model = f'model/data_dim{str(dim)}_lr0{str(lr)}_iter{str(epoch)}.model'

classifier = train_model(input='data/rate_train.txt',
                         opt=model,
                         model=model,
                         dim=dim, epoch=200, lr=0.5,
                         autotuneValidationFile="data/rate_valid.txt"
                         # autotuneValidationFile=None
                         )

result = classifier.test('data/rate_valid.txt')
print(f"test-all-result{result}")
#
res = classifier.test_label('data/rate_valid.txt')
print(f"test-label-res{res}")

# with open('data/rate_valid.txt',"r") as f:
#     for r in f.readlines():
#         r=r.replace("\n","")
#         print(classifier.predict(r.split(", ")[1],k=5,threshold=0.5),r.split(", ")[1])

with open('data1/excel_data.txt', "r") as f:
    for r in f.readlines():
        r = r.replace("\n", "")
        print(classifier.predict(r, k=5, threshold=0.3), r)


